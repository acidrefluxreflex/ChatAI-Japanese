{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acidrefluxreflex/ChatAI-Japanese/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JW-DZD_3wSW"
      },
      "source": [
        "# AIと会話する\n",
        "\n",
        "## 概要\n",
        "\n",
        "雑談できる人工知能は人類の夢。ということで自然言語処理を使って会話できるAIを作成した。会話の精度は改善の余地があるが、どんな話題でも一応対話することはできる。\n",
        "\n",
        "  \n",
        "\n",
        "## 技術\n",
        "\n",
        "参考記事は関数として機能を実装していたのでクラスに書き換えておいた。また字数制限によるエラーもあったので修正し、文章を生成する`generate()`関数を切り出して汎用性も高めておいた。\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## コード解説\n",
        "まずは必要ライブラリを準備する。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuxB3iMp3efk"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVfL8ksT4Ks_"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "model_name = \"rinna/japanese-gpt-1b\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fm5xsHO4Ovo"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DFYgQw0y4Tku"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a2fKrlmMCB9"
      },
      "source": [
        "## チャットボット\n",
        "会話をする部分はクラスとして実装した。文章生成と会話をそれぞれ行う２つの関数を持っている。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "NGnF4Sdx4Z-2"
      },
      "outputs": [],
      "source": [
        "class ChatBot(torch.nn.Module):\n",
        "\n",
        "   def __init__(self):\n",
        "         super(ChatBot, self).__init__()\n",
        "         \n",
        "\n",
        "   #文章生成を行う関数。元になる文章、最大文字数、最小文字数を引数にもつ。\n",
        "   def generate(self, text, max_length, min_length):\n",
        "     token_ids = tokenizer.encode(text, add_special_tokens=False, return_tensors=\"pt\")\n",
        "     with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            token_ids.to(model.device),\n",
        "            max_length=max_length,\n",
        "            min_length=min_length,\n",
        "            do_sample=True,\n",
        "            top_k=500,\n",
        "            top_p=0.95,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            bos_token_id=tokenizer.bos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            bad_word_ids=[[tokenizer.unk_token_id]]\n",
        "        )\n",
        "        output = tokenizer.decode(output_ids.tolist()[0])\n",
        "        return output\n",
        "    \n",
        "\n",
        "   def chat(self):\n",
        "     #プロフィール設定\n",
        "     name = input(\"AIの名前:\")\n",
        "     name_text = f\"あなたは{name}です。あなたの名前は{name}といいます。\"\n",
        "     hobby = input(\"AIの趣味:\")\n",
        "     hobby_text = f\"あなたの趣味は{hobby}で、休日は{hobby}をして過ごしています。\"\n",
        "     work = input(\"AIの職業:\")\n",
        "     work_text = f\"あなたの職業は{work}で、普段は{work}として生活しています。\"\n",
        "\n",
        "     print(\"AIに言いたい事を入力してください。終了したいときは未入力のままEnter\")\n",
        "     userInput = \"ッ\"\n",
        "     text = name_text + hobby_text + work_text + f\"以下は人間とあなたの会話です。人間:「こんにちは!」あなた:「はい、こんにちは」人間:「\"\n",
        "     max_length = 70\n",
        "     min_length = 40\n",
        "     \n",
        "\n",
        "     while userInput != \"\":\n",
        "       userInput = input(\">>> \")\n",
        "       if userInput == \"\":\n",
        "           print(\"会話を終了します\")\n",
        "           break\n",
        "       text += userInput + f\"」あなた:「\"\n",
        "\n",
        "       #文字数調節\n",
        "       message_gap = len(text) - max_length\n",
        "       if message_gap > 40:\n",
        "         max_length = len(text) - 30\n",
        "\n",
        "       output = self.generate(text,max_length,min_length)\n",
        "\n",
        "       #半角正則化\n",
        "       text = text.translate(str.maketrans({chr(0xFF01 + i): chr(0x21 + i) for i in range(94)}))\n",
        "       #今回の応答より前を取得\n",
        "       output = output.replace(text, \"\")\n",
        "       #最初の」までを分割する\n",
        "       outputList = []\n",
        "       for l in output:\n",
        "        outputList.append(l)\n",
        "        if l == \"」\":\n",
        "            break\n",
        "       outputSentence = \"\".join(outputList)\n",
        "       text += outputSentence + \"人間:「\"\n",
        "       message = outputSentence.replace(\"」\", \"\")\n",
        "\n",
        "       #文字数調節\n",
        "       max_length = len(message) + 70\n",
        "       min_length = len(message) + 40\n",
        "      \n",
        "       print(message)\n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7j_zubfMi8R"
      },
      "source": [
        "## 実際に会話してみる\n",
        "\n",
        "最初にAIの名前、趣味、基本的にはLINEやメッセージアプリのように返信をしていく。会話を終わらせたい時は入力なしでEnterを押せばよい。まるで既読無視だね。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZfGI8Q5S61ze"
      },
      "outputs": [],
      "source": [
        "bot = ChatBot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB91ePK4-O9-"
      },
      "outputs": [],
      "source": [
        "bot.chat()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5ti1q1fNOQ4"
      },
      "source": [
        "## 改善点\n",
        "やはりAI側の初期設定が問題だろう。より軽量のモデルとファインチューニングを組み合わせれば名前や口調を自由に変えられる。会話が長引くと、読み取る文脈も長くなって処理に時間がかかる問題もある。\n",
        "\n",
        "\n",
        "## 参考\n",
        "\n",
        "\n",
        "\n",
        "[13億パラメータのGPT日本語学習済みモデルが出たので会話応答を生成してみた - Qiita](https://qiita.com/MamoruItoi/items/a18abfedb79a57aeb91c)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMkDAfmimCl/MYZaGwx2veL",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "ChatBot.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
